{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbh6lMx0cU7wFsoZpEXceQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioshubham/SparkGCollab/blob/main/WorkingModel_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe78J9BMedB-",
        "outputId": "72f2ced7-41f6-48b5-9e9a-7ec4f86e1cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 1s (156 kB/s)\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: keras-ocr in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.0.0)\n",
            "Requirement already satisfied: essential_generators in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.0)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.50.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.3.0.post5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.66.2)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.24.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.31.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "#necessary installation steps\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "!pip install numpy\n",
        "!pip install keras-ocr\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"VideoToImages\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Function to check if two frames are identical\n",
        "def frames_identical(frame1, frame2):\n",
        "    return np.array_equal(frame1, frame2)\n",
        "\n",
        "# Function to convert video to images\n",
        "def video_to_images(video_path, output_folder,frame_file):\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "\n",
        "    # Read the first frame\n",
        "    success, frame = video_capture.read()\n",
        "    count = 0\n",
        "\n",
        "    prev_frame = None\n",
        "    # Loop through the video frames\n",
        "    while success:\n",
        "        # Write the frame to an image file\n",
        "        if prev_frame is not None and frames_identical(frame, prev_frame):\n",
        "            # Skip saving duplicate frame\n",
        "            print(f\"Skipping duplicate frame {count}\")\n",
        "        else:\n",
        "            # Convert frame to JPEG format\n",
        "            cv2.imwrite(output_folder + \"/frame%d.jpg\" % count, frame)\n",
        "            frame_time_seconds = count / fps\n",
        "            frame_time_minutes = int(frame_time_seconds // 60)\n",
        "            frame_time_seconds %= 60\n",
        "            frame_time_hours = int(frame_time_minutes // 60)\n",
        "            frame_time_minutes %= 60\n",
        "\n",
        "        # Get frame time in HH:MM:SS format\n",
        "            frame_time = \"{:02d}:{:02d}:{:02d}\".format(frame_time_hours, frame_time_minutes, int(frame_time_seconds))\n",
        "            with open(os.path.join(frame_file), \"a\") as file:\n",
        "               file.write(f\"Frame Time: {frame_time}|\")\n",
        "               file.write(f\"frame%d.jpg\\n\" % count)\n",
        "        prev_frame = frame.copy()\n",
        "\n",
        "        # Read the next frame\n",
        "        success, frame = video_capture.read()\n",
        "        count += 1\n",
        "\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "# Define paths\n",
        "video_path = \"/content/drive/My Drive/My_Folder/sample_video.mp4\"\n",
        "output_folder = \"/content/drive/My Drive/My_Folder/output_images\"\n",
        "frame_file =\"/content/drive/My Drive/My_Folder/frame_data.txt\"\n",
        "\n",
        "if os.path.exists(output_folder):\n",
        "   shutil.rmtree(output_folder)\n",
        "   os.makedirs(output_folder)\n",
        "if os.path.exists(frame_file):\n",
        "   os.remove(frame_file)\n",
        "\n",
        "# Convert video to images using Spark\n",
        "spark.sparkContext.parallelize([video_path]).foreach(lambda path: video_to_images(path, output_folder,frame_file))\n",
        "\n",
        "# Stop SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "u9TaUzeDgF7P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import gc\n",
        "\n",
        "# Function to read images from output_images directory\n",
        "def read_images_from_directory(directory):\n",
        "    images = []\n",
        "    file_names = []\n",
        "    for img_name in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, img_name)\n",
        "        img = Image.open(img_path)\n",
        "        images.append(img)\n",
        "        file_names.append(img_name)  # Extract file name\n",
        "    return images,file_names\n",
        "\n",
        "# previous frame extraction module stores frames in below mentioned directory\n",
        "directory = '/content/drive/My Drive/My_Folder/output_images'\n",
        "\n",
        "# Read images from directory\n",
        "images,file_names = read_images_from_directory(directory)\n",
        "\n",
        "def delete_file(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "# Function to perform text recognition using Pytesseract\n",
        "def recognize_text(images, file_names, output_file):\n",
        "    with open(output_file, 'a') as f:\n",
        "        for img, file_name in zip(images, file_names):\n",
        "            # Recognize text using Pytesseract\n",
        "            text = pytesseract.image_to_string(img, lang='eng', config='--psm 6').replace('\\n', '').strip()\n",
        "            # Write filename and text to output file\n",
        "            f.write(f\"{file_name} ### {text}\\n\")\n",
        "            del file_name,text\n",
        "            gc.collect()\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = \"/content/drive/My Drive/My_Folder/output.txt\"\n",
        "\n",
        "# Delete the output file if it exists\n",
        "delete_file(output_file)\n",
        "\n",
        "texts = recognize_text(images, file_names, output_file)\n",
        "\n",
        "\n",
        "# Cleanse the text by removing unwanted characters\n",
        "def cleanse_text(text):\n",
        "    if text is None:\n",
        "        return \"\"  # Return empty string if text is None\n",
        "    else:\n",
        "        # Remove '\\n' and '\\x0c' characters and strip leading/trailing whitespace\n",
        "        return text.replace('\\n', '').replace('\\x0c', '').strip()"
      ],
      "metadata": {
        "id": "KqP5BtP8iXGu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"VideoPlayer\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define a function to open the video link in a new tab with a specific start time\n",
        "def open_video_link(video_id, start_time=None):\n",
        "    if start_time is None:\n",
        "        video_link = f\"https://drive.google.com/file/d/{video_id}/preview\"\n",
        "    else:\n",
        "        video_link = f\"https://drive.google.com/file/d/{video_id}/preview#t={start_time}\"\n",
        "    html_code = f''\n",
        "    display(HTML(html_code))\n",
        "\n",
        "# Provide the ID of your video hosted on Google Drive\n",
        "google_drive_video_id = \"1iw0c9KM6kU2PxLB_13YAaTdHnc0uvZ5q\"  # Example ID\n",
        "#https://drive.google.com/file/d/1iw0c9KM6kU2PxLB_13YAaTdHnc0uvZ5q/view?usp=drive_link\n",
        "\n",
        "# Open the video link in a new tab without specifying the start time\n",
        "open_video_link(google_drive_video_id)\n",
        "\n",
        "# Prompt the user to manually start the video and then enter the start time (in seconds)\n",
        "input(\"Manually start the video by clicking the play button, then press Enter to continue...\")\n",
        "\n",
        "\n",
        "# Load the text file as a DataFrame\n",
        "text_file_path = \"/content/drive/MyDrive/My_Folder/output.txt\"  # Replace with the actual path to your file\n",
        "text_df = spark.read.text(text_file_path)\n",
        "\n",
        "# Prompt the user to enter the text to search for\n",
        "search_text = input(\"Enter the text to search for: \").strip().upper()\n",
        "\n",
        "# Define a function to extract frame number and text from each line\n",
        "def extract_frame_text(line):\n",
        "    parts = line.split(\"###\")\n",
        "    if len(parts) == 2:\n",
        "        frame_number, text = parts\n",
        "        return (frame_number.strip(), text.strip())\n",
        "    return (None, None)\n",
        "\n",
        "# Apply the extraction function and filter out None values\n",
        "frame_text_df = text_df.rdd.map(lambda row: extract_frame_text(row.value)).filter(lambda x: x[1] is not None).toDF([\"FrameNumber\", \"Text\"])\n",
        "\n",
        "# Filter the DataFrame to find the first occurrence of the search text\n",
        "matching_row = frame_text_df.filter(frame_text_df[\"Text\"].contains(search_text)).first()\n",
        "\n",
        "if matching_row is None:\n",
        "    print(f\"The text '{search_text}' was not found in the video.\")\n",
        "else:\n",
        "    frame_number = matching_row[\"FrameNumber\"]\n",
        "    print(f\"The text '{search_text}' was found in frame number: {frame_number}\")\n",
        "\n",
        "    # Load the data_frame.txt file as a DataFrame\n",
        "    data_frame_path = \"/content/drive/MyDrive/My_Folder/frame_data.txt\"  # Replace with the actual path to your file\n",
        "    data_frame_df = spark.read.text(data_frame_path)\n",
        "\n",
        "    # Extract frame number from the search result\n",
        "    frame_number_to_search = frame_number.split(\".\")[0]  # Assuming frame_number is in the format \"frameX.jpg\"\n",
        "\n",
        "    # Filter the DataFrame to find the corresponding timestamp\n",
        "    timestamp_row = data_frame_df.filter(data_frame_df[\"value\"].contains(frame_number_to_search)).first()\n",
        "\n",
        "    if timestamp_row is None:\n",
        "        print(f\"Timestamp not found for frame number: {frame_number}\")\n",
        "    else:\n",
        "        timestamp = timestamp_row[\"value\"].split(\"|\")[0].strip().replace('Frame Time:','')\n",
        "        print(timestamp)\n",
        "        # Split the time string into hours, minutes, and seconds\n",
        "        hours, minutes, seconds = map(int, timestamp.split(\":\"))\n",
        "\n",
        "        # Convert hours, minutes, and seconds to seconds and sum them up\n",
        "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "\n",
        "        # Continue playing the video from the user-entered time\n",
        "        open_video_link(google_drive_video_id, total_seconds)\n",
        "\n",
        "# Stop SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "x3tzNNbWrW32",
        "outputId": "798a7299-3c7f-405c-9725-bec1e172a5a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually start the video by clicking the play button, then press Enter to continue...\n",
            "Enter the text to search for: communicate\n",
            "The text 'COMMUNICATE' was found in frame number: frame120.jpg\n",
            " 00:00:04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    }
  ]
}