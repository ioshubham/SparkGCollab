{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioshubham/SparkGCollab/blob/main/mp4_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE1:\n",
        "Below Module sets the necessary installations and spark imports**"
      ],
      "metadata": {
        "id": "96FjU4YEax5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#necessary installation steps\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "!pip install numpy\n",
        "!pip install keras-ocr\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "NaFtR57TsXyQ",
        "outputId": "abf6fd93-9a28-4efd-bdba-3a95b9092dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [773 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,624 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,356 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,048 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,085 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,902 kB]\n",
            "Fetched 10.0 MB in 3s (3,193 kB/s)\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting keras-ocr\n",
            "  Downloading keras_ocr-0.9.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras-ocr)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras-ocr)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.50.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n",
            "Collecting pyclipper (from keras-ocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.66.2)\n",
            "Collecting validators (from keras-ocr)\n",
            "  Downloading validators-0.24.0-py3-none-any.whl (27 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras-ocr)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.31.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n",
            "Installing collected packages: pyclipper, essential_generators, validators, keras-applications, efficientnet, keras-ocr\n",
            "Successfully installed efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras-ocr-0.9.3 pyclipper-1.3.0.post5 validators-0.24.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,854 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 122102 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 2 : Extracts every frame from the input mp4 and stores it in output_images directory and also stores the frame info in frame_data.txt in the format \" timestamp of the frame| frame name**\n",
        "\n",
        "Prerequisites:\n",
        "1. upload the video only in \"/content/drive/My Drive/My_Folder/\" and save it as sample_video.mp4\n"
      ],
      "metadata": {
        "id": "IStco9CebJiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"VideoToImages\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Function to check if two frames are identical\n",
        "def frames_identical(frame1, frame2):\n",
        "    return np.array_equal(frame1, frame2)\n",
        "\n",
        "# Function to convert video to images\n",
        "def video_to_images(video_path, output_folder,frame_file):\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "\n",
        "    # Read the first frame\n",
        "    success, frame = video_capture.read()\n",
        "    count = 0\n",
        "\n",
        "    prev_frame = None\n",
        "    # Loop through the video frames\n",
        "    while success:\n",
        "        # Write the frame to an image file\n",
        "        if prev_frame is not None and frames_identical(frame, prev_frame):\n",
        "            # Skip saving duplicate frame\n",
        "            print(f\"Skipping duplicate frame {count}\")\n",
        "        else:\n",
        "            # Convert frame to JPEG format\n",
        "            cv2.imwrite(output_folder + \"/frame%d.jpg\" % count, frame)\n",
        "            frame_time_seconds = count / fps\n",
        "            frame_time_minutes = int(frame_time_seconds // 60)\n",
        "            frame_time_seconds %= 60\n",
        "            frame_time_hours = int(frame_time_minutes // 60)\n",
        "            frame_time_minutes %= 60\n",
        "\n",
        "        # Get frame time in HH:MM:SS format\n",
        "            frame_time = \"{:02d}:{:02d}:{:02d}\".format(frame_time_hours, frame_time_minutes, int(frame_time_seconds))\n",
        "            with open(os.path.join(frame_file), \"a\") as file:\n",
        "               file.write(f\"Frame Time: {frame_time}|\")\n",
        "               file.write(f\"frame%d.jpg\\n\" % count)\n",
        "        prev_frame = frame.copy()\n",
        "\n",
        "        # Read the next frame\n",
        "        success, frame = video_capture.read()\n",
        "        count += 1\n",
        "\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "# Define paths\n",
        "video_path = \"/content/drive/My Drive/My_Folder/sample_video.mp4\"\n",
        "output_folder = \"/content/drive/My Drive/My_Folder/output_images\"\n",
        "frame_file =\"/content/drive/My Drive/My_Folder/frame_data.txt\"\n",
        "\n",
        "if os.path.exists(output_folder):\n",
        "   shutil.rmtree(output_folder)\n",
        "   os.makedirs(output_folder)\n",
        "if os.path.exists(frame_file):\n",
        "   os.remove(frame_file)\n",
        "\n",
        "# Convert video to images using Spark\n",
        "spark.sparkContext.parallelize([video_path]).foreach(lambda path: video_to_images(path, output_folder,frame_file))\n",
        "\n",
        "# Stop SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "jsc6a2sBBix9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 3: It reads each and every frame present in output_images dir created by module 2 and extratcs the text in each frame and stores in output.txt in the format \"frame name###text\"**\n"
      ],
      "metadata": {
        "id": "MjZQQqlncC_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import gc\n",
        "\n",
        "# Function to read images from output_images directory\n",
        "def read_images_from_directory(directory):\n",
        "    images = []\n",
        "    file_names = []\n",
        "    for img_name in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, img_name)\n",
        "        img = Image.open(img_path)\n",
        "        images.append(img)\n",
        "        file_names.append(img_name)  # Extract file name\n",
        "    return images,file_names\n",
        "\n",
        "# previous frame extraction module stores frames in below mentioned directory\n",
        "directory = '/content/drive/My Drive/My_Folder/output_images'\n",
        "\n",
        "# Read images from directory\n",
        "images,file_names = read_images_from_directory(directory)\n",
        "\n",
        "def delete_file(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "# Function to perform text recognition using Pytesseract\n",
        "def recognize_text(images, file_names, output_file):\n",
        "    with open(output_file, 'a') as f:\n",
        "        for img, file_name in zip(images, file_names):\n",
        "            # Recognize text using Pytesseract\n",
        "            text = pytesseract.image_to_string(img, lang='eng', config='--psm 6').replace('\\n', '').strip()\n",
        "            # Write filename and text to output file\n",
        "            f.write(f\"{file_name} ### {text}\\n\")\n",
        "            del file_name,text\n",
        "            gc.collect()\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = \"/content/drive/My Drive/My_Folder/output.txt\"\n",
        "\n",
        "# Delete the output file if it exists\n",
        "delete_file(output_file)\n",
        "\n",
        "texts = recognize_text(images, file_names, output_file)\n",
        "\n",
        "\n",
        "# Cleanse the text by removing unwanted characters\n",
        "def cleanse_text(text):\n",
        "    if text is None:\n",
        "        return \"\"  # Return empty string if text is None\n",
        "    else:\n",
        "        # Remove '\\n' and '\\x0c' characters and strip leading/trailing whitespace\n",
        "        return text.replace('\\n', '').replace('\\x0c', '').strip()"
      ],
      "metadata": {
        "id": "yWZoOeFy5MI0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 4: It plays the input video when executed and prompts the user to search for the text and fetches the respective frame info and timestamp of the frame at which text is occuring and haults the video at that point**\n",
        "\n",
        "Prerequisite:\n",
        "1. The input video should be uploaded only in google drive with the name \"sample_vide.mp4\" under /content/drive/MyDrive/My_Folder/o\n",
        "2. Get the video Id manually from the google drive and paste in row 19 \"google_drive_video_id \" variable"
      ],
      "metadata": {
        "id": "kKYJFnE3cvz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"VideoPlayer\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define a function to open the video link in a new tab with a specific start time\n",
        "def open_video_link(video_id, start_time=None):\n",
        "    if start_time is None:\n",
        "        video_link = f\"https://drive.google.com/file/d/{video_id}/preview\"\n",
        "    else:\n",
        "        video_link = f\"https://drive.google.com/file/d/{video_id}/preview#t={start_time}\"\n",
        "    html_code = f'<iframe src=\"{video_link}\" width=\"640\" height=\"480\"></iframe>'\n",
        "    display(HTML(html_code))\n",
        "\n",
        "# Provide the ID of your video hosted on Google Drive\n",
        "google_drive_video_id = \"1HQ2vtkNXBcuLFMEZM8lxtidyu8gaqBl3\"  # Example ID\n",
        "#https://drive.google.com/file/d/1iw0c9KM6kU2PxLB_13YAaTdHnc0uvZ5q/view?usp=drive_link\n",
        "#12WQ7x8FYbgqAC4mCDn0f9Yuzvlu9WSLR\n",
        "#1HQ2vtkNXBcuLFMEZM8lxtidyu8gaqBl3\n",
        "\n",
        "# Open the video link in a new tab without specifying the start time\n",
        "open_video_link(google_drive_video_id)\n",
        "\n",
        "# Prompt the user to manually start the video and then enter the start time (in seconds)\n",
        "input(\"Manually start the video by clicking the play button, then press Enter to continue...\")\n",
        "\n",
        "\n",
        "# Load the text file as a DataFrame\n",
        "text_file_path = \"/content/drive/MyDrive/My_Folder/output.txt\"  # Replace with the actual path to your file\n",
        "text_df = spark.read.text(text_file_path)\n",
        "\n",
        "# Prompt the user to enter the text to search for\n",
        "search_text = input(\"Enter the text to search for: \").strip().upper()\n",
        "\n",
        "# Define a function to extract frame number and text from each line\n",
        "def extract_frame_text(line):\n",
        "    parts = line.split(\"###\")\n",
        "    if len(parts) == 2:\n",
        "        frame_number, text = parts\n",
        "        return (frame_number.strip(), text.strip().upper())\n",
        "    return (None, None)\n",
        "\n",
        "# Apply the extraction function and filter out None values\n",
        "frame_text_df = text_df.rdd.map(lambda row: extract_frame_text(row.value)).filter(lambda x: x[1] is not None).toDF([\"FrameNumber\", \"Text\"])\n",
        "\n",
        "# Filter the DataFrame to find the first occurrence of the search text\n",
        "matching_row = frame_text_df.filter(frame_text_df[\"Text\"].contains(search_text)).first()\n",
        "\n",
        "if matching_row is None:\n",
        "    print(f\"The text '{search_text}' was not found in the video.\")\n",
        "else:\n",
        "    frame_number = matching_row[\"FrameNumber\"]\n",
        "    print(f\"The text '{search_text}' was found in frame number: {frame_number}\")\n",
        "\n",
        "    # Load the data_frame.txt file as a DataFrame\n",
        "    data_frame_path = \"/content/drive/MyDrive/My_Folder/frame_data.txt\"  # Replace with the actual path to your file\n",
        "    data_frame_df = spark.read.text(data_frame_path)\n",
        "\n",
        "    # Extract frame number from the search result\n",
        "    frame_number_to_search = frame_number.split(\".\")[0]  # Assuming frame_number is in the format \"frameX.jpg\"\n",
        "\n",
        "    # Filter the DataFrame to find the corresponding timestamp\n",
        "    timestamp_row = data_frame_df.filter(data_frame_df[\"value\"].contains(frame_number_to_search)).first()\n",
        "\n",
        "    if timestamp_row is None:\n",
        "        print(f\"Timestamp not found for frame number: {frame_number}\")\n",
        "    else:\n",
        "        timestamp = timestamp_row[\"value\"].split(\"|\")[0].strip().replace('Frame Time:','')\n",
        "        print(timestamp)\n",
        "        # Split the time string into hours, minutes, and seconds\n",
        "        hours, minutes, seconds = map(int, timestamp.split(\":\"))\n",
        "\n",
        "        # Convert hours, minutes, and seconds to seconds and sum them up\n",
        "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "\n",
        "        # Continue playing the video from the user-entered time\n",
        "        open_video_link(google_drive_video_id, total_seconds)\n",
        "\n",
        "# Stop SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "mPM7nTbfHZbn",
        "outputId": "91c6ba09-3317-4a04-d31f-ab57aeeb96c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=\"https://drive.google.com/file/d/1HQ2vtkNXBcuLFMEZM8lxtidyu8gaqBl3/preview\" width=\"640\" height=\"480\"></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually start the video by clicking the play button, then press Enter to continue...\n",
            "Enter the text to search for: comPlicaTed\n",
            "The text 'COMPLICATED' was found in frame number: frame92.jpg\n",
            " 00:00:04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=\"https://drive.google.com/file/d/1HQ2vtkNXBcuLFMEZM8lxtidyu8gaqBl3/preview#t=4\" width=\"640\" height=\"480\"></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}